{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ds2UKTzoWTPB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciWdLSuEgY3z",
        "outputId": "ac0b5367-1eb1-4fd0-9651-ace2c46a1fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "# Location of Zip File\n",
        "drive_path = \"/content/gdrive/MyDrive/Colab Notebooks/GSoC\"\n",
        "os.chdir(drive_path)\n",
        "!unzip -q 'lens'"
      ],
      "metadata": {
        "id": "4jKaanvbgae5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "8euHOAfJhOU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/gdrive/MyDrive/GSoC/lenses\"\n",
        "train_data = datasets.ImageFolder(train_dir,transform=transform)\n",
        "# train_loader = torch.utils.data.DataLoader(train_data,shuffle=True,batch_size=32, num_workers=2)"
      ],
      "metadata": {
        "id": "3WPrNrNLg4pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import numpy as np\n",
        "validation_split = .1\n",
        "shuffle_dataset = True\n",
        "random_seed= 42\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(train_data)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32,num_workers=2,sampler=train_sampler)\n",
        "validation_loader = torch.utils.data.DataLoader(train_data, batch_size=32,num_workers=2,sampler=valid_sampler)"
      ],
      "metadata": {
        "id": "2jEEmcP2qDtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(validation_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8rZ22LmB6Gn",
        "outputId": "4369b364-215c-43e8-8d94-540c401d2d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Vit_model = torchvision.models.vit_b_16(pretrained=True)\n",
        "Vit_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuP-IPB7hGSE",
        "outputId": "14519ecb-ac5e-4258-8f60-e016e0c63994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionTransformer(\n",
              "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "  (encoder): Encoder(\n",
              "    (dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): Sequential(\n",
              "      (encoder_layer_0): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_1): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_2): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_3): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_4): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_5): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_6): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_7): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_8): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_9): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_10): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_11): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  )\n",
              "  (heads): Sequential(\n",
              "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "Vit_model.head =  nn.Linear(768,2)\n",
        "Vit_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fCm9oV6hLsN",
        "outputId": "f8ac283a-4cdc-4a4b-b11f-9d547e13297c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionTransformer(\n",
              "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "  (encoder): Encoder(\n",
              "    (dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): Sequential(\n",
              "      (encoder_layer_0): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_1): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_2): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_3): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_4): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_5): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_6): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_7): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_8): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_9): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_10): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_11): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  )\n",
              "  (heads): Sequential(\n",
              "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
              "  )\n",
              "  (head): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "# Vit_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3-Nogvlhmzg",
        "outputId": "d3113add-3a1e-4298-b8f0-645dc507cd2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DXfs2BuQDWm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(Vit_model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "hsRmg8l0hppg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(20):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        output = Vit_model(inputs)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.7f' %\n",
        "                  (epoch + 1, i + 1, running_loss ))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training of Vision Transformer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54-v1mlQhvxd",
        "outputId": "debd12f7-361e-4f0b-fe76-742f42684f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 87.3940804\n",
            "[1,   200] loss: 71.4630967\n",
            "[2,   100] loss: 71.5474192\n",
            "[2,   200] loss: 71.5153617\n",
            "[3,   100] loss: 70.0857508\n",
            "[3,   200] loss: 69.6185375\n",
            "[4,   100] loss: 69.5072957\n",
            "[4,   200] loss: 69.2332034\n",
            "[5,   100] loss: 69.6309339\n",
            "[5,   200] loss: 69.3402918\n",
            "[6,   100] loss: 67.6816031\n",
            "[6,   200] loss: 68.2261437\n",
            "[7,   100] loss: 67.4812344\n",
            "[7,   200] loss: 66.4854941\n",
            "[8,   100] loss: 65.9390634\n",
            "[8,   200] loss: 65.3473342\n",
            "[9,   100] loss: 64.4267110\n",
            "[9,   200] loss: 63.5199547\n",
            "[10,   100] loss: 63.3275600\n",
            "[10,   200] loss: 58.7384424\n",
            "[11,   100] loss: 56.2808935\n",
            "[11,   200] loss: 52.2123962\n",
            "[12,   100] loss: 50.7994626\n",
            "[12,   200] loss: 48.7779187\n",
            "[13,   100] loss: 49.1120362\n",
            "[13,   200] loss: 42.4585393\n",
            "[14,   100] loss: 41.1360990\n",
            "[14,   200] loss: 41.2689725\n",
            "[15,   100] loss: 36.6025240\n",
            "[15,   200] loss: 37.7779073\n",
            "[16,   100] loss: 32.0650440\n",
            "[16,   200] loss: 35.4010422\n",
            "[17,   100] loss: 31.6817361\n",
            "[17,   200] loss: 28.6255918\n",
            "[18,   100] loss: 28.7241528\n",
            "[18,   200] loss: 29.0890903\n",
            "[19,   100] loss: 26.6156179\n",
            "[19,   200] loss: 26.1755899\n",
            "[20,   100] loss: 22.3168257\n",
            "[20,   200] loss: 23.7037348\n",
            "Finished Training of Vision Transformer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(ResNet_model.state_dict(), \"/content/gdrive/MyDrive/Documentation/ResNet\")\n",
        "torch.save(Vit_model, \"/content/gdrive/MyDrive/Colab Notebooks/GSoC/Vit_final\")"
      ],
      "metadata": {
        "id": "E7XWkmzGkqhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_model = torch.load(\"/content/gdrive/MyDrive/Colab Notebooks/GSoC/Vit_final\")\n",
        "vit_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dQDS-Ckk0Tq",
        "outputId": "6f4c8af8-d976-4f8d-f5f9-d59ce3b5d995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionTransformer(\n",
              "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "  (encoder): Encoder(\n",
              "    (dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): Sequential(\n",
              "      (encoder_layer_0): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_1): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_2): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_3): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_4): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_5): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_6): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_7): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_8): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_9): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_10): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_11): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  )\n",
              "  (heads): Sequential(\n",
              "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
              "  )\n",
              "  (head): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in validation_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = vit_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print('Accuracy of the network on the validation images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtmVp5glk9Wm",
        "outputId": "eae23ea2-6927-464e-fc9c-15ca635d53de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the validation images: 89 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import sklearn\n",
        "from sklearn.metrics import roc_curve \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import torch.nn.functional as F\n",
        "correct = 0\n",
        "total = 0\n",
        "labels = []\n",
        "y_scores1 = []\n",
        "y_scores2 = []\n",
        "with torch.no_grad():\n",
        "    for data in validation_loader:\n",
        "        images, label = data[0].to(device), data[1].to(device)\n",
        "        outputs = vit_model(images)\n",
        "        prob1 = F.softmax(outputs,dim=1)[:,0]\n",
        "        prob2 = F.softmax(outputs,dim=1)[:,1]\n",
        "        y_score1 = prob1.cpu().detach().numpy()\n",
        "        y_score2 = prob2.cpu().detach().numpy()\n",
        "        label = label.cpu().numpy()\n",
        "        y_scores1 = np.concatenate((y_scores1, y_score1))\n",
        "        y_scores2 = np.concatenate((y_scores2, y_score2))\n",
        "        labels = np.concatenate((labels, label))"
      ],
      "metadata": {
        "id": "mQLoXnDVA5FX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr1, tpr1,_= roc_curve(label_binarize(labels, classes=range(2))[:,0], y_scores2)"
      ],
      "metadata": {
        "id": "q85bO2BxEUu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import auc\n",
        "ans = auc(fpr1,tpr1)\n",
        "print(ans)\n",
        "print(\"ROC graph\")\n",
        "plt.plot(fpr1,tpr1,marker='.')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate' )\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "hyBbNRGbDE2Z",
        "outputId": "ca83319a-364d-4db9-dd37-dd861ee1f9d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9659512835285833\n",
            "ROC graph\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgJElEQVR4nO3dfZxWdZ3/8dd7YBDFQQlQSOSuqEAwhUkwf924mmG5mmkq1m6WxW5lWz+tx7rZmj9L17Lazc1NoXxorXiTaVFh7m7rTaUgjOINkIWjgygq4iggIjfz+f1xzuDFxTXXXNPMua6ZOe/n4zEPzvec73XO58BwPtf5fs/5fhURmJlZftXVOgAzM6stJwIzs5xzIjAzyzknAjOznHMiMDPLuYG1DqCrRowYEePHj691GGZmfUpTU9MLETGy1LY+lwjGjx/PsmXLah2GmVmfIqmlo21uGjIzyzknAjOznHMiMDPLOScCM7OccyIwM8u5zBKBpGskPS/p0Q62S9IVklZLeljS9KxiMTOzjmV5R3AtMLvM9uOBSenPXOAHGcZi1mVNLa1ceedqmlpaax2KWaa/j5m9RxAR90gaX6bKScCPIxkHe7Gk/SWNjoh1WcVk+dDU0sri5g3MmjicGeOGAbBgyRpuf3Qdx08dzZkzx3a4rnAfp119HzvbAgGTRzfQMLi+2qdiBsCmrdv547ObiIC96uu4/lOzdv1u94RavlB2EPBUQXltum6PRCBpLsldA2PHji3ebDlS6iJfvL34Ar5l206e3LAFgN/9+QXm3fM4wB7rDhw6eNd+nnhhMzvbkrk6Anhh82tOBFYzG7fuIP11ZPuONhY3b+g3iaBiETEPmAfQ2NjomXT6qaaWVq66+3FWPvMyew8ayCePmrDbN/VKvqWXuoBv3d62W50XX9m2x7FffGXbbomg+Jfs2CmjuPTkad06P7O/VFNLKx/94WK272ijfmAdsyYO79H91zIRPA0cXFAek66zHGpqaeWUH9y727qv3PbIbt/UK/mWXuoCPvWN+/GV2x7Zte784yfv2n/huuKkM2fefWzfGdQPEKdMH9PdUzT7i80YN4zrPzWr7N1wd9QyESwEzpF0IzATeNn9A/nT3tRz92PPl9xe+E29km/ppS7g7f9pSvUHdNRHMGPcMG6Ye2Rm//HMumrGuGGZ/R4qqzmLJd0AvBcYATwHfA2oB4iIqyQJ+D7Jk0VbgE9ERKejyTU2NoYHnet9CtvuH3t2U4cXWHi9k/aQ0UOZ//sndn3LL+XSk6ft2kfxRf6GuUd22E/gC7jZ7iQ1RURjyW19bfJ6J4LepamllZ89sJYb719Dqev5+OH77Nb2/tzGrbs6acsZMmgAF3xwSsmneXyRN+u6comgT3QWW+9y2aJV/GbFsxx28P788uF1Zb/RF3fCluqobSeS5p+BdfDjs2eWvNBneXtslldOBNYlX7zxQX6+/BmAir7ZF3fCLliyZrdO2gF10NYG9QPERSdOpXXLNn/bN6syJwLrUHEzzGWLVu1KAh0ZNEB88qgJrFi3sWQfQXu5vQ/hraMa3NRjVmPuI7CSmlpaOSPtmK0THNCwF89ufK1kXZF8sz/9HWP5cMFTOmbWe7iPwLpscfMGtu9MviS0BbRu2V6y3qUnT3Nzjlkf50SQM5U8dbNgyRoWLHl9etNBA+v4xDvHc9U9zbvWSXDJh6aVfDzUzPoWJ4J+ptyFvpIhGko93rmzrY33HTKKscOHcNPSNRw4dDB/9543+Q7ArJ9wIuij2sfleX7jViaMGMKGV7bt9oJWqQt9JUM0lHq8c2db0lT0uaPf7DsAs37IiaCPaX+Ba8GSNbvWPbT2ZSAZRbNdqQt9JUM0FD/eCcmjnT09yJWZ9R5OBL1UqSEbRHKxr/Q5r+ILfSUDqbV/47/m9828uqONQ0YPdTOQWT/nRNALNbW08pGr7i05ZENnCl/QKr7QVzqQ2pkzx7oJyCxHnAh6icKx+Fu3bO9SEpg0cgij9t+7ohe0PESDmRVzIqiBppZWvnrbIzzVuoVjJx/I3xw5nlN/cG/FTT7tRg3diw8ddhDnf2Dybut9oTezrnAiqLLiztifL3+GRY+sK5sEJo9qYETDXgwfMognXnjFj2+aWY9yIqiC9mafJ9ZvZvX6V/bYvm1nx2lgYB184+RpvuibWWacCDJWagrGYu+eNILFzRt2JYQx+w/mhEPfSMPe9R66wcwy50SQkfZ+gD89t6lsvXdPGsGPz57pCVfMrGacCDJQ6qWsUj502Bv5tzMOB/w0j5nVjhNBD+ssCbxhn3qG7l3P7ENG7fG0j5lZLTgR9JCmllYuu30VS59s7bDOwDqY//F3+Ju/mfUqTgTdVGrsn2KHjdmP9x0yyu3/ZtYrORH8Bdo7dv/83CZ+sfyZDt8BEHDJyR6z38x6NyeCLiqcwrEcT9xiZn2FE0EX3frA2k6TwBHjh/GPx092M5CZ9QlOBF2wYMkaru+gL6BOMOcIT95uZn2PE0EFLlu0iuuXtLDptZ17bBs1dC8OHbO/x/4xsz7LiaCE9s7gTa9u55cPP8PTL20tWW9AnbjyozOcAMysT3MiSLVf/IftM4h//sWju+b27YiAr5801UnAzPo8JwIqfxKonZ8IMrP+xIkAWNy8oeIk4CeCzKy/yXUiKJwnoF2doK5O7NwZ1AmmHrQfR04c7iGhzazfyjQRSJoNfA8YAPwwIi4r2j4WuA7YP61zfkQsyjKmdh3NE9AWcOK00Uw6sMEXfjPLhcwSgaQBwJXA+4C1wFJJCyNiZUG1rwI3R8QPJE0BFgHjs4qp0NV3P97htuVPvbRreGgzs/6uLsN9HwGsjojmiNgG3AicVFQngKHp8n7AMxnGs5vnNpZ+JBRg9iGjqhWGmVnNZdk0dBDwVEF5LTCzqM5FwH9J+jwwBDi21I4kzQXmAowd2zNP6hw5cTgPrX15V3nSyCFsbwvPE2BmuVPrzuI5wLUR8R1JRwI/kTQ1ItoKK0XEPGAeQGNjY2WP95TR1NLK/N837yoPqIPLTn27+wPMLJeybBp6Gji4oDwmXVfobOBmgIi4DxgMjMgwJiB5XHRnQappa0vWmZnlUZaJYCkwSdIESYOAM4CFRXXWAMcASJpMkgjWZxgTAMP2GbRbuX5gHbMmDs/6sGZmvVJmiSAidgDnAHcAq0ieDloh6WJJJ6bVzgM+Lekh4AbgrIjodtNPOU0trfzzL16fU7hOcNFfH+JmITPLrUz7CNJ3AhYVrbuwYHklcFSWMRQrbhaKgNYt26oZgplZr5Jl01CvVNwE5GYhM8u73CWCx57dtFv5k+8c72YhM8u13CWCm5buPsPYinUbaxSJmVnvkKtE0NTSysMFL5EBHDJ6aAe1zczyIVeJYHHzBoofSWrYu74msZiZ9Ra5SgSzJg5HBeVB7ig2M6v5EBNVNWPcMCaPbmD95tc4bsooPjx9jDuKzSz3cpUIABoG19MwuJ5LTp5W61DMzHqFXDUNmZnZnpwIzMxyruJEIGmfLAMxM7Pa6DQRSHqnpJXAH9Py2yX9R+aRmZlZVVRyR/CvwPuBDQAR8RDw7iyDMjOz6qmoaSginipatTODWMzMrAYqeXz0KUnvBEJSPfAFkvkFzMysH6jkjuDvgc+RTEb/NHAY8NkMY8rUcxu3smrdRhYsWdN5ZTOzHKjkjuCtEfHRwhWSjgL+kE1I2VmwZA1PbtgCwFduS2YpO3Pm2FqGZGZWc5XcEfx7het6vdsfXVe2bGaWRx3eEUg6EngnMFLSuQWbhgIDsg4sC8dPHc3v/vzCbmUzs7wrd0cwCNiXJFk0FPxsBE7NPrSed+bMsYwfvg9DBw/k0pOnuVnIzIwydwQRcTdwt6RrI6KlijFl6sChgzlw6GAnATOzVCWdxVskXQ4cAgxuXxkRf5VZVGZmVjWVdBZfTzK8xATg/wFPAkszjMnMzKqokkQwPCJ+BGyPiLsj4pOA7wbMzPqJSpqGtqd/rpP0QeAZ4A3ZhWRmZtVUSSL4hqT9gPNI3h8YCnwxy6DMzKx6Ok0EEfGrdPFl4GjY9WaxmZn1Ax32EUgaIGmOpC9JmpquO0HSvcD3qxZhD2pqaaX5hc088cJmmlpaax2OmVmvUK6z+EfAp4DhwBWS/hP4NvCtiDi8GsH1pKaWVk67+l7Wb9rG85u2MWf+YicDMzPKNw01AodGRJukwcCzwJsiYkN1QutZi5s3sLPt9fL2HW0sbt7AjHHDaheUmVkvUO6OYFtEtAFExFaguatJQNJsSY9JWi3p/A7qnCZppaQVkhZ0Zf9dMWvicFRQrh9Yx6yJw7M6nJlZn1HujuBtkh5OlwW8KS0LiIg4tNyOJQ0ArgTeB6wFlkpaGBErC+pMAv4JOCoiWiUd0I1zKWvGuGFMHt3A+s2vcdyUUXx4+hjfDZiZUT4RTO7mvo8AVkdEM4CkG4GTgJUFdT4NXBkRrQAR8Xw3j1lWw+B6GgbXc8nJ07I8jJlZn1Ju0LnuDjR3EFA41/FaYGZRnbcASPoDydDWF0XEb4p3JGkuMBdg7FgPFmdm1pMqmrw+QwOBScB7gTnAfEn7F1eKiHkR0RgRjSNHjqxuhGZm/VyWieBp4OCC8ph0XaG1wMKI2B4RTwB/IkkMZmZWJRUlAkl7S3prF/e9FJgkaYKkQcAZwMKiOj8nuRtA0giSpqLmLh7HzMy6odNEIOmvgeXAb9LyYZKKL+h7iIgdwDnAHcAq4OaIWCHpYkknptXuADZIWgncCXy5r76nYGbWV1Uy6NxFJE8A3QUQEcslTahk5xGxCFhUtO7CguUAzk1/zMysBippGtoeES8XrYssgjEzs+qr5I5ghaQzgQHpC2D/ANybbVhmZlYtldwRfJ5kvuLXgAUkw1F/McOYzMysiiq5I3hbRFwAXJB1MGZmVn2V3BF8R9IqSV9vn5fAzMz6j04TQUQcTTIz2XrgakmPSPpq5pGZmVlVVPRCWUQ8GxFXAH9P8k7BheU/YWZmfUUlL5RNlnSRpEdIJq+/l2S4CDMz6wcq6Sy+BrgJeH9EPJNxPGZmVmWdJoKIOLIagZiZWW10mAgk3RwRp6VNQoVvElc0Q5mZmfUN5e4IvpD+eUI1AjEzs9rosLM4Itali5+NiJbCH+Cz1QnPzMyyVsnjo+8rse74ng7EzMxqo1wfwWdIvvlPlPRwwaYG4A9ZB2ZmZtVRro9gAXA78C/A+QXrN0XEi5lGlYGmllaaX9iM0uUZ44bVOiQzs16hXNNQRMSTwOeATQU/SHpD9qH1nKaWVk67+l7Wb9rG85u2MWf+YppaWmsdlplZr9DZHcEJQBPJ46Mq2BbAxAzj6lGLmzews+318vYdbSxu3uC7AjMzyiSCiDgh/bOiaSl7s1kThycvP6Tl+oF1zJo4vJYhmZn1Gp2+WSzpKGB5RLwi6WPAdODfImJN5tH1kBnjhjF5dAPrN7/GcVNG8eHpY3w3YGaWquTx0R8AWyS9HTgPeBz4SaZRZaBhcD0TR+zLJSdPcxIwMytQSSLYEREBnAR8PyKuJHmE1MzM+oFKRh/dJOmfgL8B3iWpDqjPNiwzM6uWSu4ITieZuP6TEfEsyVwEl2calZmZVU0lU1U+C1wP7CfpBGBrRPw488jMzKwqKpmh7DTgfuAjwGnAEkmnZh2YmZlVRyV9BBcA74iI5wEkjQT+B7gly8DMzKw6KukjqGtPAqkNFX7OzMz6gEruCH4j6Q7ghrR8OrAou5DMzKyaKpmz+MuSPgz8n3TVvIi4LduwzMysWsrNRzAJ+DbwJuAR4EsR8XS1AjMzs+oo19Z/DfAr4BSSEUj/vas7lzRb0mOSVks6v0y9UySFpMauHsPMzLqnXNNQQ0TMT5cfk/RAV3YsaQBwJclUl2uBpZIWRsTKonoNwBeAJV3Zv5mZ9YxyiWCwpMN5fR6CvQvLEdFZYjgCWB0RzQCSbiQZr2hlUb2vA98EvtzF2M3MrAeUSwTrgO8WlJ8tKAfwV53s+yDgqYLyWmBmYQVJ04GDI+LXkjpMBJLmAnMBxo4d28lhzcysK8pNTHN0lgdOB6/7LnBWZ3UjYh4wD6CxsTE6qW5mZl2Q5YthTwMHF5THpOvaNQBTgbskPQnMAha6w9jMrLqyTARLgUmSJkgaBJwBLGzfGBEvR8SIiBgfEeOBxcCJEbEsw5jMzKxIZokgInYA5wB3AKuAmyNihaSLJZ2Y1XHNzKxrKpmzWMBHgYkRcbGkscCoiLi/s89GxCKKhqOIiAs7qPveiiI2M7MeVckdwX8ARwJz0vImkvcDzMysH6hk0LmZETFd0oMAEdGatvmbmVk/UMkdwfb0LeGAXfMRtGUalZmZVU0lieAK4DbgAEmXAL8HLs00KjMzq5pKhqG+XlITcAzJ8BIfiohVmUdmZmZVUclTQ2OBLcAvC9dFxJosAzMzs+qopLP41yT9AwIGAxOAx4BDMozLzMyqpJKmoWmF5XSguM9mFpGZmVVVl98sToefntlpRTMz6xMq6SM4t6BYB0wHnsksIjMzq6pK+ggaCpZ3kPQZ/CybcMzMrNrKJoL0RbKGiPhSleIxM7Mq67CPQNLAiNgJHFXFeMzMrMrK3RHcT9IfsFzSQuCnwCvtGyPi1oxjMzOzKqikj2AwsIFkjuL29wkCcCIwM+sHyiWCA9Inhh7l9QTQzvMGm5n1E+USwQBgX3ZPAO2cCMzM+olyiWBdRFxctUjMzKwmyr1ZXOpOwMzM+plyieCYqkVhZmY102EiiIgXqxmImZnVRpcHnTMzs/4lN4lg09btPP3SqzS1tNY6FDOzXiUXiaCppZVV6zaxtvVV5sxf7GRgZlYgF4ng1gfW7nrxYduONm59YG1N4zEz601ykQiK337z23BmZq/LRSI4ZfqYXS9FDBogTpk+pqbxmJn1JpUMOtfnzRg3jMmjG9i4dQffO+NwZowbVuuQzMx6jVwkAoCGwfU0DK53EjAzK5KLpiEzM+tYpolA0mxJj0laLen8EtvPlbRS0sOSfitpXJbxmJnZnjJLBOl8x1cCxwNTgDmSphRVexBojIhDgVuAb2UVj5mZlZblHcERwOqIaI6IbcCNwEmFFSLizojYkhYXA36cx8ysyrJMBAcBTxWU16brOnI2cHupDZLmSlomadn69et7MEQzM+sVncWSPgY0ApeX2h4R8yKiMSIaR44cWd3gzMz6uSwfH30aOLigPCZdtxtJxwIXAO+JiNcyjMfMzErI8o5gKTBJ0gRJg4AzgIWFFSQdDlwNnBgRz2cYi5mZdSCzRBARO4BzgDuAVcDNEbFC0sWSTkyrXQ7sC/xU0nJJCzvYXbc9t3Erq9ZtZMGSNVkdwsysT8r0zeKIWAQsKlp3YcHysVkev92CJWt4ckPycNJXbnsEgDNnjq3Goc3Mer1e0VmctdsfXVe2bGaWZ7lIBIeMHlq2bGaWZ7lIBA1715ctm5nlWS4SwbB9BpUtm5nlWS4SQeuWbbuW64rKZmZ5l4tEMGvicOrSKcoG1dcxa+Lw2gZkZtaL5GJimhnjhvG2UZ6hzMyslFwkAvAMZWZmHclF0xDApq3befqlV2lqaa11KGZmvUouEkFTSyur1m1ibeurzJm/2MnAzKxALhLBrQ+sJdLlbTvauPWBtTWNx8ysN8lFIli/6bWyZTOzPMtFIjAzs47lIhGMaNirbNnMLM9ykQimvnG/smUzszzLRSJY8czLZctmZnmWi0QQnZTNzPIsF4nglOljSIcaYtAAccr0MTWNx8ysN8nFEBMzxg1j8miPNWRmVkouEgF4rCEzs47komkIPNaQmVlHcpEICscaOmPefU4GZmYFcpEIrr778V1PCm3fGVx99+M1jcfMrDfJRSJoXr+5bNnMLM9ykQjeMGRQ2bKZWZ7lIhHsv8+gsmUzszzLRSJ4acu2smUzszzLRSJ48ZVtZctmZnmWi0QwYeS+ZctmZnmWi0Rw9FsPKFs2M8uzXCSC1oI+gbqisplZ3mWaCCTNlvSYpNWSzi+xfS9JN6Xbl0gan0UcsyYOpy4dfnRQfR2zJg7P4jBmZn1SZolA0gDgSuB4YAowR9KUompnA60R8WbgX4FvZhHLjHHDOKBhL/YaWMdZR473wHNmZgWyvCM4AlgdEc0RsQ24ETipqM5JwHXp8i3AMZJED1uwZA3PbnyN13a0cdU9zSxYsqanD2Fm1mdlmQgOAp4qKK9N15WsExE7gJeBPdptJM2VtEzSsvXr13c5kNsfXVe2bGaWZ32iszgi5kVEY0Q0jhw5ssufP37q6LJlM7M8y3JimqeBgwvKY9J1peqslTQQ2A/Y0NOBnDlzLJDcCRw/dfSuspmZZZsIlgKTJE0gueCfAZxZVGch8HHgPuBU4H8jIpO55c+cOdYJwMyshMwSQUTskHQOcAcwALgmIlZIuhhYFhELgR8BP5G0GniRJFmYmVkVZTpncUQsAhYVrbuwYHkr8JEsYzAzs/L6RGexmZllx4nAzCznnAjMzHLOicDMLOeU0dOamZG0Hmj5Cz8+AnihB8PpC3zO+eBzzofunPO4iCj5Rm6fSwTdIWlZRDTWOo5q8jnng885H7I6ZzcNmZnlnBOBmVnO5S0RzKt1ADXgc84Hn3M+ZHLOueojMDOzPeXtjsDMzIo4EZiZ5Vy/TASSZkt6TNJqSeeX2L6XpJvS7Uskja9BmD2qgnM+V9JKSQ9L+q2kcbWIsyd1ds4F9U6RFJL6/KOGlZyzpNPSf+sVkhZUO8aeVsHv9lhJd0p6MP39/kAt4uwpkq6R9LykRzvYLklXpH8fD0ua3u2DRkS/+iEZ8vpxYCIwCHgImFJU57PAVenyGcBNtY67Cud8NLBPuvyZPJxzWq8BuAdYDDTWOu4q/DtPAh4EhqXlA2oddxXOeR7wmXR5CvBkrePu5jm/G5gOPNrB9g8AtwMCZgFLunvM/nhHcASwOiKaI2IbcCNwUlGdk4Dr0uVbgGMkqYox9rROzzki7oyILWlxMcmMcX1ZJf/OAF8HvglsrWZwGanknD8NXBkRrQAR8XyVY+xplZxzAEPT5f2AZ6oYX4+LiHtI5mfpyEnAjyOxGNhfUrfm3+2PieAg4KmC8tp0Xck6EbEDeBkYXpXoslHJORc6m+QbRV/W6Tmnt8wHR8SvqxlYhir5d34L8BZJf5C0WNLsqkWXjUrO+SLgY5LWksx/8vnqhFYzXf3/3qlMJ6ax3kfSx4BG4D21jiVLkuqA7wJn1TiUahtI0jz0XpK7vnskTYuIl2oZVMbmANdGxHckHUky6+HUiGirdWB9RX+8I3gaOLigPCZdV7KOpIEkt5MbqhJdNio5ZyQdC1wAnBgRr1Uptqx0ds4NwFTgLklPkrSlLuzjHcaV/DuvBRZGxPaIeAL4E0li6KsqOeezgZsBIuI+YDDJ4Gz9VUX/37uiPyaCpcAkSRMkDSLpDF5YVGch8PF0+VTgfyPthemjOj1nSYcDV5Mkgb7ebgydnHNEvBwRIyJifESMJ+kXOTEiltUm3B5Rye/2z0nuBpA0gqSpqLmKMfa0Ss55DXAMgKTJJIlgfVWjrK6FwN+mTw/NAl6OiHXd2WG/axqKiB2SzgHuIHni4JqIWCHpYmBZRCwEfkRy+7iapFPmjNpF3H0VnvPlwL7AT9N+8TURcWLNgu6mCs+5X6nwnO8AjpO0EtgJfDki+uzdboXnfB4wX9L/Jek4Pqsvf7GTdANJMh+R9nt8DagHiIirSPpBPgCsBrYAn+j2Mfvw35eZmfWA/tg0ZGZmXeBEYGaWc04EZmY550RgZpZzTgRmZjnnRGC9kqSdkpYX/IwvU3dzDxzvWklPpMd6IH1Dtav7+KGkKenyV4q23dvdGNP9tP+9PCrpl5L276T+YX19NE7Lnh8ftV5J0uaI2Len65bZx7XAryLiFknHAd+OiEO7sb9ux9TZfiVdB/wpIi4pU/8sklFXz+npWKz/8B2B9QmS9k3nUXhA0iOS9hhpVNJoSfcUfGN+V7r+OEn3pZ/9qaTOLtD3AG9OP3tuuq9HJX0xXTdE0q8lPZSuPz1df5ekRkmXAXuncVyfbtuc/nmjpA8WxHytpFMlDZB0uaSl6Rjzf1fBX8t9pIONSToiPccHJd0r6a3pm7gXA6ensZyexn6NpPvTuqVGbLW8qfXY2/7xT6kfkrdil6c/t5G8BT803TaC5K3K9jvazemf5wEXpMsDSMYbGkFyYR+Srv9H4MISx7sWODVd/giwBJgBPAIMIXkrewVwOHAKML/gs/ulf95FOudBe0wFddpjPBm4Ll0eRDKK5N7AXOCr6fq9gGXAhBJxbi44v58Cs9PyUGBgunws8LN0+Szg+wWfvxT4WLq8P8lYRENq/e/tn9r+9LshJqzfeDUiDmsvSKoHLpX0bqCN5JvwgcCzBZ9ZClyT1v15RCyX9B6SyUr+kA6tMYjkm3Qpl0v6Ksk4NWeTjF9zW0S8ksZwK/Au4DfAdyR9k6Q56XddOK/bge9J2guYDdwTEa+mzVGHSjo1rbcfyWBxTxR9fm9Jy9PzXwX8d0H96yRNIhlmob6D4x8HnCjpS2l5MDA23ZfllBOB9RUfBUYCMyJiu5IRRQcXVoiIe9JE8UHgWknfBVqB/46IORUc48sRcUt7QdIxpSpFxJ+UzHXwAeAbkn4bERdXchIRsVXSXcD7gdNJJlqBZLapz0fEHZ3s4tWIOEzSPiTj73wOuIJkAp47I+LktGP9rg4+L+CUiHiskngtH9xHYH3FfsDzaRI4GthjzmUl8zA/FxHzgR+STPe3GDhKUnub/xBJb6nwmL8DPiRpH0lDSJp1fifpjcCWiPhPksH8Ss0Zuz29MynlJpKBwtrvLiC5qH+m/TOS3pIes6RIZpv7B+A8vT6UevtQxGcVVN1E0kTW7g7g80pvj5SMSms550RgfcX1QKOkR4C/Bf5Yos57gYckPUjybft7EbGe5MJ4g6SHSZqF3lbJASPiAZK+g/tJ+gx+GBEPAtOA+9Mmmq8B3yjx8XnAw+2dxUX+i2RioP+JZPpFSBLXSuABJZOWX00nd+xpLA+TTMzyLeBf0nMv/NydwJT2zmKSO4f6NLYVadlyzo+PmpnlnO8IzMxyzonAzCznnAjMzHLOicDMLOecCMzMcs6JwMws55wIzMxy7v8D7fWlqE0Nc5wAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}